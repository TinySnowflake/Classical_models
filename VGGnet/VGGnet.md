## VGGnet介绍及Tensorflow实现
### VGGnet介绍
* 背景
ILSVRC 2014的第二名是Karen Simonyan和 Andrew Zisserman实现的卷积神经网络，现在称其为VGGNet。它主要的贡献是展示出网络的深度是算法优良性能的关键部分。
他们最好的网络包含了16个卷积/全连接层。网络的结构非常一致，从头到尾全部使用的是3x3的卷积和2x2的汇聚。他们的预训练模型是可以在网络上获得并在Caffe中使用的。
VGGNet不好的一点是它耗费更多计算资源，并且使用了更多的参数，导致更多的内存占用（140M）。其中绝大多数的参数都是来自于第一个全连接层。
后来发现这些全连接层即使被去除，对于性能也没有什么影响，这样就显著降低了参数数量。
目前使用比较多的网络结构主要有ResNet(152-1000层），GooleNet(22层），VGGNet（19层）。大多数模型都是基于这几个模型上改进，采用新的优化算法，多模型融合等。

* 结构介绍
以下介绍参考[链接](https://blog.csdn.net/wcy12341189/article/details/56281618)
VGG是在从Alex-net发展而来的网络。主要修改一下两个方面：
1，在第一个卷基层层使用更小的filter尺寸和间隔（3*3）； 2，在整个图片和multi-scale上训练和测试图片。
**3*3 filter:  **
引入cs231n上面一段话：
**几个小滤波器卷积层的组合比一个大滤波器卷积层好： **
假设你一层一层地重叠了3个3x3的卷积层（层与层之间有非线性激活函数）。在这个排列下，第一个卷积层中的每个神经元都对输入数据体有一个3x3的视野。
第二个卷积层上的神经元对第一个卷积层有一个3x3的视野，也就是对输入数据体有5x5的视野。同样，在第三个卷积层上的神经元对第二个卷积层有3x3的视野，
也就是对输入数据体有7x7的视野。假设不采用这3个3x3的卷积层，二是使用一个单独的有7x7的感受野的卷积层，那么所有神经元的感受野也是7x7，但是就有一些缺点:
首先，多个卷积层与非线性的激活层交替的结构，比单一卷积层的结构更能提取出深层的更好的特征。
其次，假设所有的数据有C个通道，那么单独的7x7卷积层将会包含  7*7*C=49C2个参数，而3个3x3的卷积层的组合仅有个3\*（3*3*C）=27 C2个参数。直观说来，最好选择带有小滤波器的卷积层组合，而不是用一个带有大的滤波器的卷积层。前者可以表达出输入数据中更多个强力特征，使用的参数也更少。唯一的不足是，在进行反向传播时，中间的卷积层可能会导致占用更多的内存。
**1\*1 filter**: 作用是在不影响输入输出维数的情况下，对输入线进行线性形变，然后通过Relu进行非线性处理，增加网络的非线性表达能力。 Pooling：2*2，间隔s=2。

补充1\*1卷积核的作用：
1. 可用于升/降维度，通过指定filter(核)的多少，输出通道尺寸不变而升/降通道个数，而实现特征的升/降维。在inception-net中使用1\*1卷积核的此用法
2. 可当全连接使用，而不需要通过flat展开tensor来实现，只需要前一层使用与通道尺寸一样的卷积核/pooling核，从而输出通道形状为1\*1(通道数由核的多少来决定)。后续再使用1\*1卷积核，便会实现全连接的作用，在目标检测中使用1\*1卷积核的此用法。
![](https://img-blog.csdn.net/20171101185932018?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhhbmd3ZWkxNWho/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
### VGG16结构
下面算一下每一层的像素值计算：
输入：224*224*3
1. conv3 - 64（卷积核的数量）：kernel size:3 stride:1 pad:1
像素：（224-3+2*1）/1+1=224 224*224*64
参数： （3*3*3）*64 =1728
2. conv3 - 64：kernel size:3 stride:1 pad:1
像素： （224-3+1*2）/1+1=224 224*224*64
参数： （3*3*64）*64 =36864
3. pool2 kernel size:2 stride:2 pad:0
像素： （224-2）/2 = 112 112*112*64
参数： 0
4.conv3-128:kernel size:3 stride:1 pad:1
像素： （112-3+2*1）/1+1 = 112 112*112*128
参数： （3*3*64）*128 =73728
5.conv3-128:kernel size:3 stride:1 pad:1
像素： （112-3+2*1）/1+1 = 112 112*112*128
参数： （3*3*128）*128 =147456
6.pool2: kernel size:2 stride:2 pad:0
像素： （112-2）/2+1=56 56*56*128
参数：0
7.conv3-256: kernel size:3 stride:1 pad:1
像素： （56-3+2*1）/1+1=56 56*56*256
参数：（3*3*128）*256=294912
8.conv3-256: kernel size:3 stride:1 pad:1
像素： （56-3+2*1）/1+1=56 56*56*256
参数：（3*3*256）*256=589824
9.conv3-256: kernel size:3 stride:1 pad:1
像素： （56-3+2*1）/1+1=56 56*56*256
参数：（3*3*256）*256=589824
10.pool2: kernel size:2 stride:2 pad:0
像素：（56 - 2）/2+1=28 28*28*256
参数：0
11. conv3-512:kernel size:3 stride:1 pad:1
像素：（28-3+2*1）/1+1=28 28*28*512
参数：（3*3*256）*512 = 1179648
12. conv3-512:kernel size:3 stride:1 pad:1
像素：（28-3+2*1）/1+1=28 28*28*512
参数：（3*3*512）*512 = 2359296
13. conv3-512:kernel size:3 stride:1 pad:1
像素：（28-3+2*1）/1+1=28 28*28*512
参数：（3*3*512）*512 = 2359296
14.pool2: kernel size:2 stride:2 pad:0
像素：（28-2）/2+1=14 14*14*512
参数： 0
15. conv3-512:kernel size:3 stride:1 pad:1
像素：（14-3+2*1）/1+1=14 14*14*512
参数：（3*3*512）*512 = 2359296
16. conv3-512:kernel size:3 stride:1 pad:1
像素：（14-3+2*1）/1+1=14 14*14*512
参数：（3*3*512）*512 = 2359296
17. conv3-512:kernel size:3 stride:1 pad:1
像素：（14-3+2*1）/1+1=14 14*14*512
参数：（3*3*512）*512 = 2359296
18.pool2:kernel size:2 stride:2 pad:0
像素：（14-2）/2+1=7 7*7*512
参数：0
19.FC: 4096 neurons
像素：1*1*4096
参数：7*7*512*4096 = 102760448
20.FC: 4096 neurons
像素：1*1*4096
参数：4096*4096 = 16777216
21.FC：1000 neurons
像素：1*1*1000
参数：4096*1000=4096000
总共参数数量大约138M左右。
### VGG19结构图
<center>![这里写图片描述](https://img-blog.csdn.net/20180913192125151?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTQ2OTI3Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
### VGG网络特点：
1. 使用较小的卷积核及pooling核，层数加深(VGG16-16层VGG19-19层)，从而使模型快速收敛。
2. 但是引起模型参数多，占用内存大。不过除去VGG的最后两层全连接，会使模型精简很多，因此VGG模型多被用来迁移学习。
### 参考方向
[https://blog.csdn.net/zhangwei15hh/article/details/78417789](https://blog.csdn.net/zhangwei15hh/article/details/78417789)
[https://blog.csdn.net/wcy12341189/article/details/56281618](https://blog.csdn.net/wcy12341189/article/details/56281618)
[代码参考链接](https://github.com/XunNie/Classical_models/tree/master/VGGnet)
